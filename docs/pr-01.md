pr-01 spec: repo scaffold + packaging + shared utilities

goal

establish a working flat-layout python package (niels_gpt) with reproducible dev workflow, minimal shared utilities, and a regression test that guarantees imports + basic utilities keep working. this PR must eliminate the need for ad-hoc import/path hacks in later PRs.

non-goals
	•	no tokenizer/chat/model/datasets/training code
	•	no cuda support (mac mps + cpu only)
	•	no numpy dependency
	•	no CI setup (optional later)

constraints
	•	python: >=3.11
	•	package name: niels-gpt (import as niels_gpt)
	•	only dependencies in this PR:
	•	runtime: torch
	•	dev: pytest
	•	prefer uv in README examples, but do not hard-require it for usage
	•	keep code small and explicit; no clever build machinery beyond standard pyproject.toml

files to create/modify (only these)

create/modify:
	•	pyproject.toml
	•	README.md
	•	niels_gpt/__init__.py
	•	niels_gpt/device.py
	•	niels_gpt/rng.py
	•	niels_gpt/config.py
	•	niels_gpt/paths.py
	•	tests/test_scaffold.py

do not touch any other files.

⸻

required behavior

packaging/imports
	•	repo uses flat layout with a real package directory: niels_gpt/
	•	pip install -e . works (editable install)
	•	after install, import niels_gpt works from anywhere
	•	tests must not rely on mutating sys.path

niels_gpt/device.py

def get_device() -> str:
    """
    returns:
      - "mps" if torch.backends.mps.is_available() and is_built()
      - else "cpu"
    never returns "cuda"
    """

niels_gpt/rng.py

def set_seed(seed: int) -> None:
    """
    sets seeds for:
      - python random
      - torch (torch.manual_seed)
    must not import numpy.
    """

def make_generator(seed: int, device: str | None = None) -> "torch.Generator":
    """
    returns a torch.Generator seeded with `seed`.
    if device is provided, construct generator for that device when supported;
    if not supported, fall back to cpu generator.
    """

notes:
	•	determinism across devices is not required. we just want repeatability on a given machine.
	•	batching later will use torch.Generator passed explicitly.

niels_gpt/config.py

use dataclasses and json. no pydantic.

from dataclasses import dataclass
from typing import Any

@dataclass(frozen=True)
class ModelConfig:
    V: int = 256
    T: int = 256
    C: int = 256
    L: int = 4
    H: int = 4
    d_ff: int = 1024
    dropout: float = 0.1
    rope_theta: float = 10000.0

@dataclass(frozen=True)
class TrainConfig:
    seed: int = 42
    B: int = 32
    total_steps_smoke: int = 1000
    total_steps: int = 20000
    eval_every: int = 200
    ckpt_every: int = 1000
    base_lr: float = 3e-4
    warmup_steps: int = 200
    min_lr: float = 3e-5
    grad_clip: float = 1.0
    p_train: dict[str, float] = None  # filled by factory below

def default_p_train() -> dict[str, float]:
    """
    returns p_train with primer weight 0.02 and wiki/roam at 80/20 of remaining:
      {"wiki": 0.784, "roam": 0.196, "primer": 0.020}
    """

def to_dict(obj: Any) -> dict:
    """dataclass -> plain dict (recursive for dataclasses only)."""

def save_json(path: str, data: dict) -> None:
    """write utf-8 json with indent=2 and sorted keys."""

def load_json(path: str) -> dict:
    """read json and return dict."""

rules:
	•	if TrainConfig.p_train is None, callers are expected to use default_p_train().
	•	do not bake file paths into config (that’s paths.py).

niels_gpt/paths.py

use pathlib.Path.

from pathlib import Path

REPO_ROOT: Path  # resolved at runtime from this file location

ROAM_DIR: Path = REPO_ROOT / ".roam-data"
PRIMER_PATH: Path = REPO_ROOT / "data" / "primer.txt"
CHECKPOINT_DIR: Path = REPO_ROOT / "checkpoints"
CONFIG_DIR: Path = REPO_ROOT / "configs"

def ensure_dirs() -> None:
    """
    create CHECKPOINT_DIR and CONFIG_DIR if missing.
    do not create ROAM_DIR or data/ (those are user-provided).
    """

README.md

must include:
	•	quickstart with uv (recommended):
	•	create venv
	•	install editable
	•	run tests
	•	fallback instructions with pip
	•	explicitly state: mac uses mps if available, otherwise cpu

keep it short.

⸻

tests: tests/test_scaffold.py

pytest must lock these invariants.

required tests:
	1.	imports work

	•	import niels_gpt
	•	from niels_gpt.device import get_device
	•	from niels_gpt.paths import REPO_ROOT, ROAM_DIR, PRIMER_PATH, CHECKPOINT_DIR, CONFIG_DIR, ensure_dirs

	2.	device is valid

	•	get_device() returns "mps" or "cpu"

	3.	seed repeatability (torch)

	•	call set_seed(42)
	•	create a generator g1 = make_generator(123)
	•	draw torch.randint(0, 10, (5,), generator=g1)
	•	recreate g2 = make_generator(123) and draw again
	•	assert tensors equal

	4.	ensure_dirs creates expected dirs

	•	call ensure_dirs()
	•	assert CHECKPOINT_DIR.exists() and CONFIG_DIR.exists()

acceptance command:
	•	pytest -q passes
