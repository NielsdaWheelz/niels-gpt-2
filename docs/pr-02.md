pr-02 spec: tokenizer + chat formatting/parsing

goal

implement the byte-level tokenizer and the chat transcript formatting/parsing utilities as pure, testable modules within the niels_gpt package, with pytest tests that lock exact behavior.

non-goals
	•	no dataset loading
	•	no model code
	•	no training loop
	•	no primer splitting (the <dialogue> delimiter is not used in this PR)
	•	no cli/web code

repo conventions
	•	flat layout with niels_gpt package
	•	tests use pytest
	•	only depend on: torch, pytest (stdlib ok)

files to create/modify

create:
	•	niels_gpt/tokenizer.py
	•	niels_gpt/chat_format.py
	•	tests/test_tokenizer.py
	•	tests/test_chat_format.py

do not touch other files.

⸻

api contracts

niels_gpt/tokenizer.py

import torch

def encode(text: str) -> torch.LongTensor:
    """
    utf-8 encode to bytes; each byte is a token id.
    returns: 1D int64 tensor on cpu, shape (n,), values in [0..255].
    """

def decode(ids: torch.LongTensor) -> str:
    """
    decode ids -> bytes -> utf-8 string for display.
    rule: bytes(ids).decode("utf-8", errors="replace")

    validation:
    - ids must be a torch.Tensor
    - ids must be 1D
    - all values must be ints in [0..255]
    otherwise raise ValueError.
    """

edge cases:
	•	encode("") returns an empty 1D tensor (shape == (0,))
	•	decode(torch.tensor([], dtype=torch.long)) returns ""

niels_gpt/chat_format.py

roles:
	•	allowed roles: "system" | "user" | "assistant" only (lowercase)
	•	invalid role → raise ValueError

formatting rules
	•	transcript line format: "{role}: {content}\n" for every complete message
	•	generation prompt ends with exactly: "assistant: " (one space, no newline)
	•	role tags must be at position 0 or immediately after \n (formatter guarantees this)

special rule (option 2):
	•	if the last message is {"role":"assistant", "content": ""}, treat it as the prompt:
	•	include "assistant: " and do not append an extra "assistant: "
	•	ensure there is no trailing newline after that prompt

signature:

def format_chat(messages: list[dict]) -> str:
    """
    messages: list of dicts with keys "role" and "content"
    returns transcript ending with exact prompt "assistant: " (no newline).
    """

reply extraction rules
signature:

def extract_assistant_reply(generated_text: str) -> str:
    """
    generated_text includes the prompt prefix.
    find the last non-empty assistant reply, where a reply is the text after
    "assistant: " up to the earliest subsequent turn tag among:
      - "\nsystem: "
      - "\nuser: "
      - "\nassistant: "
    return value is stripped of leading/trailing whitespace via .strip().

    trailing empty "assistant: " prompts are ignored (common in generation).
    if "assistant: " is not present, raise ValueError.
    if all assistant occurrences are empty, return "".
    """


⸻

tests (must be exact, not “approx”)

tests/test_tokenizer.py
	•	test_encode_basic_ascii:
	•	encode("A") equals tensor([65])
	•	test_encode_empty:
	•	shape (0,), dtype torch.int64
	•	test_decode_basic_ascii:
	•	decode(tensor([65, 66])) == "AB"
	•	test_decode_empty:
	•	decode(empty_tensor) == ""
	•	test_decode_rejects_non_1d:
	•	decode(torch.zeros((2,2), dtype=torch.long)) raises ValueError
	•	test_decode_rejects_out_of_range:
	•	decode(torch.tensor([256], dtype=torch.long)) raises ValueError
	•	decode(torch.tensor([-1], dtype=torch.long)) raises ValueError

tests/test_chat_format.py
	•	test_format_chat_basic:
input:

[
  {"role":"system","content":"x"},
  {"role":"user","content":"y"},
]

output must equal:

system: x\n
user: y\n
assistant: 

(i.e. string literal: "system: x\nuser: y\nassistant: ")

	•	test_format_chat_last_empty_assistant_is_prompt:
input:

[
  {"role":"system","content":"x"},
  {"role":"user","content":"y"},
  {"role":"assistant","content":""},
]

output must equal "system: x\nuser: y\nassistant: " (no duplicate assistant tag, no trailing newline)

	•	test_format_chat_rejects_invalid_role:
invalid role raises ValueError
	•	test_extract_assistant_reply_stops_at_next_tag:
generated:
"system: x\nuser: y\nassistant: hello there\nuser: z\nassistant: "
reply must equal "hello there" (strip applied)
	•	test_extract_assistant_reply_uses_last_assistant_tag:
generated:
"assistant: first\nuser: u\nassistant: second\n"
reply must equal "second"
	•	test_extract_assistant_reply_raises_if_missing:
missing "assistant: " raises ValueError

⸻

commands (acceptance)
	•	pytest -q must pass.
