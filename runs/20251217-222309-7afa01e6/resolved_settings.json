{
  "banned_token_ids": [
    3,
    4,
    5
  ],
  "generated_at_utc": "2025-12-17T22:23:09.346597+00:00",
  "model_cfg": {
    "C": 32,
    "H": 4,
    "L": 1,
    "T": 8,
    "V": 256,
    "d_ff": 64,
    "dropout": 0.1,
    "rope_theta": 10000.0
  },
  "overrides": {
    "data": {
      "caches": {
        "pretrain_token_cache": "/var/folders/49/nvdz6j9n3ms760pt9y2l95p40000gn/T/tmpirx1x6tv/streams"
      },
      "mix_pretrain": {
        "primer": 0.1,
        "roam": 0.2,
        "wiki": 0.7
      },
      "val_pretrain_source": "wiki"
    },
    "model": {
      "C": 32,
      "H": 4,
      "L": 1,
      "T": 8,
      "V": 256,
      "d_ff": 64,
      "dropout": 0.1,
      "rope_theta": 10000.0
    },
    "training": {
      "pretrain": {
        "accum_steps": 1,
        "base_lr": 0.001,
        "ckpt_every": 5,
        "eval_every": 5,
        "eval_steps": 1,
        "grad_clip": 1.0,
        "log_every": 1,
        "micro_B": 2,
        "min_lr": 1e-05,
        "seed": 1,
        "total_steps": 5,
        "warmup_steps": 0
      }
    }
  },
  "overrides_source": null,
  "phase": "pretrain",
  "run_id": "20251217-222309-7afa01e6",
  "settings": {
    "benchmark": {
      "binary_search_max_micro_B": 256,
      "candidate_T": [
        512,
        1024
      ],
      "candidate_model_dims": [
        {
          "C": 384,
          "H": 6,
          "L": 8
        },
        {
          "C": 512,
          "H": 8,
          "L": 8
        },
        {
          "C": 512,
          "H": 8,
          "L": 12
        }
      ],
      "checkpointing_modes": [
        false,
        true
      ],
      "lr": 0.0003,
      "max_micro_B": 256,
      "seed": 42,
      "steps_measure": 10,
      "steps_warmup": 2,
      "timeout_s": 20.0
    },
    "data": {
      "allow_missing_idx": false,
      "caches": {
        "pretrain_token_cache": "/var/folders/49/nvdz6j9n3ms760pt9y2l95p40000gn/T/tmpirx1x6tv/streams",
        "raw_cache_dir": "/Users/nnandal/Documents/code/niels-gpt/data/cache/hf",
        "sft_token_cache": "/Users/nnandal/Documents/code/niels-gpt/data/cache/sft",
        "streams_token_cache": "/Users/nnandal/Documents/code/niels-gpt/data/cache/streams"
      },
      "chunking": {
        "pack_to_T": true,
        "stride": 1
      },
      "dolly": {
        "dataset_id": "databricks/databricks-dolly-15k",
        "include_system": false,
        "max_examples": null,
        "split": "train"
      },
      "fineweb_edu": {
        "chunking": {
          "pack_to_T": true,
          "stride": 1
        },
        "dataset_id": "HuggingFaceFW/fineweb-edu",
        "max_bytes": null,
        "max_examples": null,
        "max_tokens": null,
        "name": "CC-MAIN-2024-10",
        "shuffle": true,
        "split": "train",
        "streaming": true
      },
      "gutenberg": {
        "chunking": {
          "pack_to_T": true,
          "stride": 1
        },
        "dataset_id": "nikolina-p/gutenberg_clean_en_splits",
        "max_bytes": null,
        "max_examples": null,
        "max_tokens": null,
        "shuffle": true,
        "split": "train",
        "streaming": true
      },
      "mix_pretrain": {
        "primer": 0.1,
        "roam": 0.2,
        "wiki": 0.7
      },
      "mix_sft": {
        "dolly": 0.2,
        "oasst1": 0.6,
        "primer": 0.2
      },
      "oasst1": {
        "dataset_id": "OpenAssistant/oasst1",
        "english_only": true,
        "max_messages": 32,
        "shuffle_trees": true,
        "split": "train",
        "take_trees": null
      },
      "primer": {
        "delimiter": "\n\n<dialogue>\n\n",
        "path": "/Users/nnandal/Documents/code/niels-gpt/data/primer.txt",
        "seed": 42,
        "val_frac": 0.1
      },
      "roam": {
        "chunking": {
          "pack_to_T": true,
          "stride": 1
        },
        "glob_pattern": "**/*.md",
        "root_dir": "/Users/nnandal/Documents/code/niels-gpt/.roam-data",
        "split_seed": 42,
        "val_frac": 0.1
      },
      "val_pretrain_source": "wiki",
      "val_sft_source": "wiki",
      "wikitext": {
        "chunking": {
          "pack_to_T": true,
          "stride": 1
        },
        "config": "wikitext-103-raw-v1",
        "dataset_id": "wikitext",
        "max_bytes": null,
        "max_examples": null,
        "max_tokens": null,
        "streaming": false,
        "test_split": "test",
        "train_split": "train",
        "val_split": "val"
      }
    },
    "generation": {
      "banned_token_ids": null,
      "max_new_tokens": 256,
      "repetition_penalty": null,
      "stop_token_id": null,
      "temperature": 0.9,
      "top_k": 50,
      "top_p": null
    },
    "model": {
      "C": 32,
      "H": 4,
      "L": 1,
      "T": 8,
      "V": 256,
      "attention": {
        "attn_type": "mha",
        "kv_cache_dtype": "fp16",
        "use_kv_cache": true
      },
      "d_ff": 64,
      "dropout": 0.1,
      "mlp_type": "swiglu",
      "norm_type": "rmsnorm",
      "rope_theta": 10000.0
    },
    "reproducibility": {
      "dataset_shuffle_buffer_size": 10000,
      "torch_matmul_precision": null,
      "torch_num_threads": null
    },
    "sft_format": {
      "allow_truncate_mid_turn": true,
      "assistant_only_loss": true,
      "ban_role_tokens_during_generation": true,
      "include_eot_in_loss": false,
      "pack_sequences": true,
      "packing_policy": "prefer_boundary_allow_truncate",
      "require_eot": true
    },
    "tokenizer": {
      "byte_fallback": true,
      "model_path": "/Users/nnandal/Documents/code/niels-gpt/artifacts/tokenizer/spm.model",
      "normalization": "nfkc",
      "special_tokens": {
        "asst": "<|asst|>",
        "eot": "<|eot|>",
        "sys": "<|sys|>",
        "usr": "<|usr|>"
      },
      "tokenizer_type": "bpe",
      "vocab_size": 16000
    },
    "training": {
      "pretrain": {
        "accum_steps": 1,
        "activation_checkpointing": false,
        "amp": true,
        "amp_dtype": "fp16",
        "base_lr": 0.001,
        "best_metric": "pretrain_val_loss",
        "best_metric_weights": null,
        "betas": [
          0.9,
          0.95
        ],
        "ckpt_every": 5,
        "decay_embeddings": true,
        "decay_norm_and_bias": true,
        "eps": 1e-08,
        "eval_batches": null,
        "eval_every": 5,
        "eval_steps": 1,
        "grad_clip": 1.0,
        "log_every": 1,
        "micro_B": 2,
        "micro_B_eval": null,
        "min_lr": 1e-05,
        "optimizer": "adamw",
        "save_best": true,
        "seed": 1,
        "total_steps": 5,
        "warmup_steps": 0,
        "weight_decay": 0.1
      },
      "sft": {
        "accum_steps": 1,
        "activation_checkpointing": false,
        "amp": true,
        "amp_dtype": "fp16",
        "base_lr": 0.0001,
        "best_metric": "sft_val_loss",
        "best_metric_weights": null,
        "betas": [
          0.9,
          0.95
        ],
        "ckpt_every": 1000,
        "decay_embeddings": true,
        "decay_norm_and_bias": true,
        "eps": 1e-08,
        "eval_batches": null,
        "eval_every": 200,
        "eval_steps": 50,
        "grad_clip": 1.0,
        "log_every": 50,
        "micro_B": 16,
        "micro_B_eval": null,
        "min_lr": 1e-05,
        "optimizer": "adamw",
        "save_best": true,
        "seed": 42,
        "total_steps": 6000,
        "warmup_steps": 120,
        "weight_decay": 0.05
      }
    }
  },
  "special_token_ids": {
    "asst": 5,
    "eot": 6,
    "sys": 3,
    "usr": 4
  },
  "stop_token_id": 6,
  "tokenizer": {
    "model_path": "/Users/nnandal/Documents/code/niels-gpt/artifacts/tokenizer/spm.model",
    "sha256": "2d1c644242d94401c6063df2e9830ef96b339c30c656dd7c49cdf3cf5b5d2ae9",
    "special_tokens": {
      "asst": "<|asst|>",
      "eot": "<|eot|>",
      "sys": "<|sys|>",
      "usr": "<|usr|>"
    }
  },
  "train_cfg": {
    "B": 2,
    "accum_steps": 1,
    "activation_checkpointing": false,
    "amp": true,
    "amp_dtype": "fp16",
    "base_lr": 0.001,
    "best_metric": "pretrain_val_loss",
    "best_metric_weights": null,
    "beta1": 0.9,
    "beta2": 0.95,
    "ckpt_every": 5,
    "decay_embeddings": true,
    "decay_norm_and_bias": true,
    "eps": 1e-08,
    "eval_batches": null,
    "eval_every": 5,
    "eval_steps": 1,
    "grad_clip": 1.0,
    "log_every": 1,
    "micro_B_eval": null,
    "min_lr": 1e-05,
    "optimizer": "adamw",
    "save_best": true,
    "seed": 1,
    "total_steps": 5,
    "warmup_steps": 0,
    "weight_decay": 0.1
  }
}